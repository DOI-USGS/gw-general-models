{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multiple runs of a General Simulation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:13:07.290171Z",
     "start_time": "2021-12-29T16:13:07.162743Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import os\n",
    "import datetime as dt\n",
    "import pickle, joblib\n",
    "\n",
    "\n",
    "# Standard data science libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import scipy.optimize as so \n",
    "import scipy.interpolate as si\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-notebook')\n",
    "\n",
    "# Options for pandas\n",
    "pd.options.display.max_columns = 20\n",
    "pd.options.display.max_rows = 200\n",
    "\n",
    "# Display all cell outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import Math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:05:42.295466Z",
     "start_time": "2021-12-29T16:05:39.121286Z"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import flopy as fp\n",
    "import statsmodels.api as sm # for lowess smoothing of plots\n",
    "from scipy.spatial import ConvexHull # to find the Pareto front\n",
    "import shapely # to operate on the parameter space\n",
    "from scipy.spatial.distance import cdist # to operate on parameter space\n",
    "from argparse import Namespace\n",
    "import json\n",
    "\n",
    "import RTD_util6 as rtd_ut # custom module with utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T12:38:57.843482Z",
     "start_time": "2021-03-04T12:38:57.830145Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mp_exe_name7 = '../Executables/modpath_7_2_001/bin/mpath7.exe'\n",
    "model_ws = 'optimal_model'\n",
    "\n",
    "with open('GenMod_metadata.txt') as json_file:\n",
    "    metadata = json.load(json_file)\n",
    "    \n",
    "src = os.path.join('model_ws', 'gsm_metadata.json')\n",
    "with open(src, 'r') as f:\n",
    "    gsm_metadata = json.load(f)   \n",
    "    \n",
    "from argparse import Namespace\n",
    "meta = Namespace(**gsm_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read metadata dictionary that was created when the model was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T12:38:57.904705Z",
     "start_time": "2021-03-04T12:38:57.845474Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "src = os.path.join(model_ws, 'gsm_metadata.json')\n",
    "with open(src, 'r') as f:\n",
    "    gsm_metadata = json.load(f)   \n",
    "    \n",
    "meta = Namespace(**gsm_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:08:20.562261Z",
     "start_time": "2021-12-29T16:08:20.551618Z"
    }
   },
   "source": [
    "Copy the GSM that was created over to the scratch directory. It will be replaced many times during the exploration of parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('model_ws/calibration_runs'):\n",
    "    shutil.rmtree('model_ws/calibration_runs')\n",
    "shutil.copytree('model_ws', 'model_ws/calibration_runs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model and extract a few variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T12:39:02.238541Z",
     "start_time": "2021-03-04T12:38:58.406134Z"
    }
   },
   "outputs": [],
   "source": [
    "sim = fp.mf6.MFSimulation.load(sim_name='mfsim.nam', version='mf6', exe_name=metadata['modflow_path'],\n",
    "                               sim_ws='model_ws/calibration_runs', strict=True, verbosity_level=0, \n",
    "                               load_only=None, verify_data=False)\n",
    "\n",
    "model = sim.get_model()\n",
    "\n",
    "dis = model.get_package('dis')\n",
    "top_ar = dis.top.array\n",
    "top = top_ar.ravel()\n",
    "nlay, nrow, ncol = dis.nlay.array, dis.nrow.array, dis.ncol.array\n",
    "delc = dis.delc.array\n",
    "delr = dis.delr.array\n",
    "\n",
    "npf = model.get_package('npf')\n",
    "k = npf.k.array\n",
    "k33 = npf.k33.array\n",
    "\n",
    "tmp = np.load(os.path.join('bedrock_flag_array.npz'))\n",
    "bedrock_index = tmp['bedrock_index']\n",
    "\n",
    "print ('   ... done') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model_grid.csv file to get the observation cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T12:39:03.032154Z",
     "start_time": "2021-03-04T12:39:02.241535Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_file = os.path.join(geo_ws, 'model_grid.csv')\n",
    "model_grid = pd.read_csv(model_file)\n",
    "model_grid.fillna(0, inplace=True)\n",
    "\n",
    "model_grid.loc[model_grid[meta.K_bdrk] == 0, meta.ibound] = 0\n",
    "model_grid.loc[model_grid[meta.K_surf] == 0, meta.ibound] = 0\n",
    "\n",
    "model_grid.loc[model_grid.ibound == 0, 'obs_type'] = np.nan\n",
    "\n",
    "topo_cells = model_grid.obs_type == 'topo'\n",
    "hydro_cells = model_grid.obs_type == 'hydro'\n",
    "\n",
    "num_topo = model_grid.obs_type.value_counts()['topo']\n",
    "num_hydro = model_grid.obs_type.value_counts()['hydro']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to update parameter values, run the model, and calculate hydro and topo errors. This updates streambed hydraulic conductivity ($K_{stream}$) also. It estimates hydraulic conductivity ($K$)  as a factor of the original parameter field. Intermediate K in bedrock layers between top and bottom are assumed to decay exponentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T12:39:03.110180Z",
     "start_time": "2021-03-04T12:39:03.034208Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_model(k_surf_mult, k_bdrk_mult, stream_mult, k_bottom_fraction, sim_ws='model_ws/calibration_runs'):\n",
    "    \n",
    "#   transform the log multipliers to real multipliers\n",
    "    k_surf_mult = 10 ** k_surf_mult\n",
    "    k_bdrk_mult = 10 ** k_bdrk_mult\n",
    "    stream_mult = 10 ** stream_mult\n",
    "    k_bottom_fraction = 10 ** k_bottom_fraction    \n",
    "    \n",
    "    # use flopy to read in the model\n",
    "    sim = fp.mf6.MFSimulation.load(sim_name='mfsim.nam', version='mf6', \n",
    "                                   exe_name=metadata['modflow_path'],\n",
    "                                   sim_ws=sim_ws, strict=True, verbosity_level=0, \n",
    "                                   load_only=None, verify_data=False)\n",
    "    model = sim.get_model()\n",
    "    dis = model.get_package('dis')\n",
    "    npf = model.get_package('npf')\n",
    "\n",
    "    # set K in each layer\n",
    "    k_top_of_bedrock = k[-gsm_metadata['num_bdrk_layers']] * k_bdrk_mult\n",
    "    k_bottom_of_bedrock = k[-1, ...] * k_bottom_fraction\n",
    "\n",
    "    grid = np.empty((nlay+1, nrow, ncol))\n",
    "    grid[0, ...] = dis.top.array\n",
    "    grid[1:, ...] = dis.botm.array\n",
    "    z = (grid[0:-1, ...] + grid[1:, ...] ) / 2\n",
    "\n",
    "    a = np.log(k_bottom_of_bedrock / k_top_of_bedrock) / (z[-1 , ...] - z[-gsm_metadata['num_bdrk_layers']])\n",
    "    c = k_top_of_bedrock * np.exp(-a * z[-gsm_metadata['num_bdrk_layers']])\n",
    "    k_exp = c * np.exp(a * z)\n",
    "\n",
    "    new_k = np.where(bedrock_index, k_exp, k_surf_mult * k)\n",
    "    npf.k = new_k\n",
    "\n",
    "    model_grid[meta.K_surf] = new_k[0, ...].ravel()\n",
    "    \n",
    "    # set drain data in each drain cell\n",
    "    drn_data = model_grid[(model_grid.order != 0) &\n",
    "                          (model_grid[meta.ibound] == 1)].copy()\n",
    "\n",
    "    # adjust streambed K based on cell K and stream_mult\n",
    "    drn_data['dcond'] = drn_data[meta.K_surf] * stream_mult * \\\n",
    "        drn_data.reach_len * drn_data.width / meta.stream_bed_thk\n",
    "    drn_data['iface'] = 6\n",
    "    drn_data = drn_data.reindex(\n",
    "        ['lay', 'row', 'col', 'stage', 'dcond', 'iface'], axis=1)\n",
    "    drn_data.rename(columns={'lay': 'k', 'row': 'i',\n",
    "                             'col': 'j', 'stage': 'stage'}, inplace=True)\n",
    "    drn_data = drn_data[drn_data.dcond > 0]\n",
    "    \n",
    "    cellid = list(zip(drn_data.k, drn_data.i, drn_data.j))\n",
    "\n",
    "    drn_data6 = pd.DataFrame({'cellid': cellid, 'stage': drn_data.stage,\n",
    "                              'dcond': drn_data.dcond, 'iface': drn_data.iface})\n",
    "    drn_recarray6 = drn_data6.to_records(index=False)\n",
    "    drn_dict6 = {0: drn_recarray6}\n",
    "\n",
    "    drn = model.get_package('drn')\n",
    "    drn.stress_period_data = drn_dict6\n",
    "\n",
    "    # run the model \n",
    "    sim.write_simulation()\n",
    "    sim.run_simulation(silent=True)\n",
    "\n",
    "    # calculate the errors\n",
    "    rtd = rtd_ut.RTD_util(sim, 'flow', 'rt')\n",
    "    rtd.get_watertable()\n",
    "    water_table = rtd.water_table\n",
    "\n",
    "    t_crit = (model_grid.obs_type =='topo') & (model_grid[meta.ibound] != 0)\n",
    "    topo_cells = t_crit.values.reshape(nrow, ncol)\n",
    "\n",
    "    h_crit = (model_grid.obs_type =='hydro') & (model_grid[meta.ibound] != 0)\n",
    "    hydro_cells = h_crit.values.reshape(nrow, ncol)\n",
    "\n",
    "    num_topo = np.count_nonzero(topo_cells)\n",
    "    num_hydro = np.count_nonzero(hydro_cells)\n",
    "\n",
    "    topo = (top_ar + meta.err_tol) < water_table\n",
    "    hydro = (top_ar - meta.err_tol) > water_table\n",
    "\n",
    "    topo_error = topo & topo_cells\n",
    "    hydro_error = hydro & hydro_cells\n",
    "\n",
    "    t = np.count_nonzero(topo_error)\n",
    "    h = np.count_nonzero(hydro_error)\n",
    "\n",
    "    topo_rate = t / num_topo\n",
    "    hydro_rate = h / num_hydro\n",
    "\n",
    "    return topo_rate, hydro_rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read optimization results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T12:39:03.149319Z",
     "start_time": "2021-03-04T12:39:03.112203Z"
    }
   },
   "outputs": [],
   "source": [
    "src = os.path.join(model_ws, 'results_df.csv')\n",
    "df = pd.read_csv(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find one set of the optimal parameters by considering where the Pareto (tradeoff) front between hydro and topo errors intersects the line of hydro error = topo error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To evaluate uncertainty\n",
    "\n",
    "Find the Pareto front where there is a tradeoff between hydro and topo errors. To do this, we must separate the two halves of the convex hull polygon.  We only want the minimum.  Do this by creating a vertical line at each point along the front (which will be at a convex hull node) and taking the minimum.  Assemble the minima into a line shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot all points in parameter space and the Pareto front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:13:13.404752Z",
     "start_time": "2021-12-29T16:13:13.376810Z"
    }
   },
   "outputs": [],
   "source": [
    "dst = os.path.join('optimal_model', 'pareto_sets.csv')\n",
    "pareto_df= pd.read_csv(dst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell shows how to loop through parameter sets on the Pareto front; however, it does not capture the results and needs to be improved. To evaluate uncertainty, travel time distributions could be calculated for each of the parameter sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the list of paramter set indices\n",
    "for i, j in df.iloc[pareto_sets].iterrows():\n",
    "    # extract the parameter set at that index and run the model with it\n",
    "    run_model(j.k_surf_mult, j.k_bdrk_mult, j.stream_mult, j.k_bottom_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "state": {
    "eaf3a954c6e44063805d67090344a922": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
