{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T21:43:12.675587Z",
     "start_time": "2020-04-02T21:43:12.672592Z"
    }
   },
   "source": [
    "# Create MODFLOW6-grid-based tiff files and model_grid.csv file from GIS data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T14:54:34.369629Z",
     "start_time": "2021-12-23T14:54:30.413122Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This first cell imports needed modules and sets a few display options\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "import os\n",
    "import datetime as dt\n",
    "import pickle, joblib\n",
    "\n",
    "# Standard data science libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import scipy.optimize as so \n",
    "import scipy.interpolate as si\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "plt.style.use('seaborn-notebook')\n",
    "\n",
    "# Options for pandas\n",
    "pd.options.display.max_columns = 20\n",
    "pd.options.display.max_rows = 50\n",
    "\n",
    "# Display all cell outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import Math\n",
    "\n",
    "import scipy.ndimage as nd\n",
    "import scipy.spatial as sp\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "import gdal\n",
    "gdal.UseExceptions()\n",
    "import flopy as fp\n",
    "\n",
    "import Genmod_Utilities as gmu\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T14:54:34.385116Z",
     "start_time": "2021-12-23T14:54:34.371488Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('GenMod_metadata.txt') as json_file:\n",
    "    metadata = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T14:38:19.227005Z",
     "start_time": "2021-09-01T14:38:19.222985Z"
    }
   },
   "source": [
    "## Specify horizontal grid resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`number_of_grid_divisions`: *integer*, The general simulation model (**GSM**) grid is based on a specified integer number of cell divisions of the grid specified by Clark and others (2018) (**natgrid**). Here the user can specifiy splitting those cells into an integer number of equal subdivisions. **natgrid** has 1000 m pixels, so for example `number_of_grid_divisions` = 4 leads to 250 m pixels in **GSM**.  \n",
    "\n",
    "Clark, B.R., Barlow, P.M., Peterson, S.M., Hughes, J.D., Reeves, H.W., and Viger, R.J., 2018, National-scale grid to support regional groundwater availability studies and a national hydrogeologic database: U.S. Geological Survey data release, https://doi.org/10.5066/F7P84B24."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T14:54:34.400479Z",
     "start_time": "2021-12-23T14:54:34.386449Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cell divisions\n",
    "number_of_grid_divisions = 1\n",
    "gsm_delxy= 1000 / number_of_grid_divisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify geospatial data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify how geospatial data will be mapped onto the model grid. Data sources are each specified in tuples in a list. There is a list for vector sources and a list for raster sources. The geospatial data in these sources will be rasterized, resampled, and reprojected onto the model grid. The rasterized values will be stored in GeoTiff files and as columns in the file `model_grid.csv`. \n",
    "\n",
    "Each vector source is specified by a tuple (which means that the values, separated by commas, are enclosed in parentheses) in a list. The elements of each tuple are\n",
    "* pathname to source (usually a shapefile but other formats are supported)\n",
    "* field name (or column or attribute or label) in the input data source that will be rasterized\n",
    "* field name for the output data to used in `model_grid.csv`; the same name is given to the GeoTiff file for that data source\n",
    "\n",
    "Raster sources are also specified in tuples, the elements of which are\n",
    "* `natgrid_pth`: *string*, location of National Groundwater Grid tif file \n",
    "\n",
    "\n",
    "* pathname to source (many formats are supported)\n",
    "* method, usually `gdal.GRA_Bilinear` or `gdal.GRA_NearestNeighbour`, although other methods are available.  See the documentation for Genmod_Utilities for other methods.\n",
    "* conversion factor by which to multiply the source (e.g., factor=100 to convert cm in the input to m in the output)\n",
    "* field name for the output data to used in `model_grid.csv`; the same name is given to the GeoTiff file for that data source\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T14:54:34.416370Z",
     "start_time": "2021-12-23T14:54:34.402405Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "natgrid_pth = os.path.join('national_spatial_data', 'grid', 'natlGrid1km.tif')\n",
    "\n",
    "# (src, attribute, name)\n",
    "\n",
    "vector_list = [\n",
    "#     (os.path.join('national_spatial_data', 'NHDPlusNationalData', 'gageloc.shp'), \n",
    "#      'REACHCODE', 'gage_id'),\n",
    "    \n",
    "#     (os.path.join('national_spatial_data', 'USGS_DS_425_SHAPES', 'Surficial_materials_K_added.shp'), \n",
    "#      'K', 'K_surf'),\n",
    "    \n",
    "#     (os.path.join('national_spatial_data', 'GLHYMPS', 'GLHYMPS_K_added.shp'), \n",
    "#      'K', 'K_glhymps'),\n",
    "]\n",
    "\n",
    "\n",
    "# (src, method, factor, name)\n",
    "\n",
    "raster_list = [\n",
    "    (os.path.join(metadata['raster_name'], 'elev_cm.tif'),\n",
    "    gdal.GRA_Bilinear, 0.01, 'ned'),\n",
    "\n",
    "    (os.path.join(metadata['raster_name'], 'cat.tif'),\n",
    "    gdal.GRA_NearestNeighbour, 1, 'catchment'),\n",
    "\n",
    "    (os.path.join('national_spatial_data', 'EffRecharge_0013_v2', 'EffRecharge_0013 (1)', '0013', 'RC_eff_0013.tif'),\n",
    "    gdal.GRA_Bilinear, 1/365.25, 'recharge'),\n",
    "\n",
    "    (os.path.join('national_spatial_data', 'b_r_Shan.tif'),\n",
    "    gdal.GRA_Bilinear, 1., 'thickness_Shang'),\n",
    "\n",
    "    (os.path.join('national_spatial_data', 'K_s_dry_mod_md.tif'),\n",
    "    gdal.GRA_Bilinear, 1., 'surf_K'),\n",
    "    \n",
    "    (os.path.join('national_spatial_data', 'K_b_dry_mod_md.tif'),\n",
    "    gdal.GRA_Bilinear, 1., 'bed_K'),    \n",
    "\n",
    "    (os.path.join(metadata['ngwm_dir'], 'k_lay_0.tif'),\n",
    "    gdal.GRA_Bilinear, 1, 'k_ngwm'),\n",
    "    \n",
    "    (os.path.join(metadata['ngwm_dir'], 'k33_lay_0.tif'),\n",
    "    gdal.GRA_Bilinear, 1, 'k33_ngwm'),\n",
    "    \n",
    "    (os.path.join(metadata['ngwm_dir'], 'botm_lay_0.tif'),\n",
    "    gdal.GRA_Bilinear, 1, 'botm_ngwm'),\n",
    "    \n",
    "    (os.path.join(metadata['ngwm_dir'], 'idomain_lay_0.tif'),\n",
    "    gdal.GRA_Bilinear, 1, 'idomain_ngwm'),\n",
    "    \n",
    "    (os.path.join(metadata['ngwm_dir'], 'ss_lay_0.tif'),\n",
    "    gdal.GRA_Bilinear, 1, 'ss_ngwm'),\n",
    "    \n",
    "    (os.path.join(metadata['ngwm_dir'], 'strt_lay_0.tif'),\n",
    "    gdal.GRA_Bilinear, 1, 'strt_ngwm'),\n",
    "    \n",
    "    (os.path.join(metadata['ngwm_dir'], 'sy_lay_0.tif'),\n",
    "    gdal.GRA_Bilinear, 1, 'k33_ngwm'),\n",
    "    \n",
    "    (os.path.join(metadata['ngwm_dir'], 'top.tif'),\n",
    "    gdal.GRA_Bilinear, 1, 'top_ngwm')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the National Groundwater Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T14:54:35.555334Z",
     "start_time": "2021-12-23T14:54:34.417367Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "natgrid = gmu.SourceProcessing()\n",
    "natgrid.read_raster(natgrid_pth)\n",
    "proj = natgrid.output_raster_prj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the model domain shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T14:54:37.190333Z",
     "start_time": "2021-12-23T14:54:35.556334Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shp = gpd.read_file(metadata['domain_name'])\n",
    "shp.to_crs(proj, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish model grid -- derived from National Groundwater Model grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the part of the national grid (**natgrid**) that contains the model domain. Establish the dimensions and cell size of the general simulation model (**gsm**) grid based on the specified number of **natgrid** cell divisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T14:54:37.206284Z",
     "start_time": "2021-12-23T14:54:37.191319Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get coordinates of origin (x0, y0) and pixel (cell) size from natgrid\n",
    "natgrid_x0, natgrid_pixelx, dum, natgrid_y0, dum, natgrid_pixely = natgrid.gt\n",
    "\n",
    "# length of sides of natgrid\n",
    "natgrid_lenx = natgrid_pixelx * natgrid.ncol\n",
    "natgrid_leny = natgrid_pixely * natgrid.nrow\n",
    "\n",
    "# number of gridlines in each direction in the gsm grid\n",
    "natgrid_number_x_lines = natgrid.ncol * number_of_grid_divisions + 1\n",
    "natgrid_number_y_lines = natgrid.nrow * number_of_grid_divisions + 1 \n",
    "\n",
    "# make an array of natgrid line coorindates\n",
    "natgrid_x_lines = np.linspace(natgrid_x0, natgrid_x0 + natgrid_lenx, natgrid_number_x_lines)\n",
    "natgrid_y_lines = np.linspace(natgrid_y0, natgrid_y0 + natgrid_leny, natgrid_number_y_lines)\n",
    "\n",
    "# min and max of bounding box around gsm domain\n",
    "gsm_minx, gsm_miny, gsm_maxx, gsm_maxy = np.squeeze(shp.bounds.values)\n",
    "\n",
    "# find the natgrid lines that bound the gsm domain\n",
    "gsm_x0 = natgrid_x_lines[natgrid_x_lines <= gsm_minx][-1]\n",
    "gsm_xm = natgrid_x_lines[natgrid_x_lines >= gsm_maxx][0]\n",
    "gsm_ym = natgrid_y_lines[natgrid_y_lines <= gsm_miny][0]\n",
    "gsm_y0 = natgrid_y_lines[natgrid_y_lines >= gsm_maxy][-1]\n",
    "\n",
    "# length of sides of gsm grid\n",
    "gsm_lenx = gsm_xm - gsm_x0\n",
    "gsm_leny = gsm_ym - gsm_y0\n",
    "\n",
    "# number of rows and columns for gsm\n",
    "gsm_ncol = np.int32(np.abs(gsm_lenx / gsm_delxy))\n",
    "gsm_nrow = np.int32(np.abs(gsm_leny / gsm_delxy)) \n",
    "\n",
    "# row and column spacinf for gsm\n",
    "gsm_delr = gsm_delxy\n",
    "gsm_delc = gsm_delxy\n",
    "\n",
    "# blank raster in memory in the shape of the gsm grid\n",
    "grid_raster = gmu.SourceProcessing(np.nan)\n",
    "grid_raster.create_raster(0, (gsm_x0, gsm_y0), gsm_delr, gsm_delc, gsm_nrow, gsm_ncol, proj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish bounding box for grid. Save the bounding box to a shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T14:54:37.334001Z",
     "start_time": "2021-12-23T14:54:37.210273Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coords = ((gsm_x0, gsm_y0), (gsm_xm, gsm_y0), (gsm_xm, gsm_ym), (gsm_x0, gsm_ym))\n",
    "polygon = gpd.GeoSeries(Polygon(coords))\n",
    "box = gpd.GeoDataFrame(geometry=polygon, crs=proj)\n",
    "box.crs = proj\n",
    "\n",
    "box.to_file(os.path.join(metadata['gis_dir'], 'clip_box.shp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish a FloPy grid object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T14:54:37.349087Z",
     "start_time": "2021-12-23T14:54:37.335936Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "delc_ar = np.ones((gsm_nrow)) * gsm_delc\n",
    "delr_ar = np.ones((gsm_ncol)) * gsm_delr\n",
    "\n",
    "ml = fp.discretization.structuredgrid.StructuredGrid(\n",
    "    delc=delc_ar, delr=delr_ar, xoff=gsm_x0, yoff=gsm_y0+gsm_leny, angrot=0, lenuni=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create drainage network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and intersect flowline file with domain outline. These are from the high resolution NHDPlus flow lines and the associated value-added attribute table (VAA). Flow lines are merged with the VAA and the resulting file is cleaned up. The merged file is converted back to a GeoDataFrame and saved as a shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T14:55:53.974665Z",
     "start_time": "2021-12-23T14:54:37.350895Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read high resolution NHDPlus flow lines\n",
    "flowlines = gpd.read_file(metadata['vector_name'], layer='NHDFlowline')\n",
    "flowlines.to_crs(crs=proj, inplace=True)\n",
    "\n",
    "# clip flow lines to the model domain and select columns\n",
    "nhd_clip = gpd.overlay(flowlines, shp)\n",
    "nhd_clip = nhd_clip[['Permanent_Identifier', 'NHDPlusID', 'ReachCode', 'ibound', 'geometry']]\n",
    "\n",
    "# check that the clipped file is not empty\n",
    "assert nhd_clip.shape[0] != 0, 'The model domain is not in the area covered by the downloaded NHDPlus'\n",
    "\n",
    "# read the VAA and select columns\n",
    "VAA_tab = gpd.read_file(metadata['vector_name'], layer='NHDPlusFlowlineVAA')\n",
    "VAA_tab = VAA_tab[['NHDPlusID', 'StreamOrde', 'MaxElevSmo', 'MinElevSmo']]\n",
    "\n",
    "# merge selected fields from the associated tables into the clipped flow lines\n",
    "# this step takes the data frame from geopandas to pandas and loses the geographic information\n",
    "nhd_clip = nhd_clip.merge(VAA_tab, how='inner', on='NHDPlusID')\n",
    "\n",
    "# convert elevation in cm to meters\n",
    "nhd_clip['maxft'] = nhd_clip.MaxElevSmo / 100.\n",
    "nhd_clip['minft'] = nhd_clip.MinElevSmo / 100.\n",
    "\n",
    "# convert the merged file back to a GeoDataFrame (geopandas) and it save as a shapefile\n",
    "nhd_clip = gpd.GeoDataFrame(nhd_clip, geometry=nhd_clip.geometry, crs=proj)\n",
    "nhd_clip.to_file(os.path.join(metadata['gis_dir'], 'NHD_clip.shp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate drain stage at cell centers and extract ancillary data. This step used FloPy's internal intersection function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T14:57:47.667016Z",
     "start_time": "2021-12-23T14:55:53.975669Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a FloPy GridIntersect object\n",
    "ix = fp.utils.gridintersect.GridIntersect(ml)\n",
    "\n",
    "# start a blank dataframe for drain data\n",
    "drains = pd.DataFrame()\n",
    "\n",
    "# loop through each stream reach and intersect with the model grid\n",
    "for index, reach in nhd_clip.iterrows():\n",
    "    reach_len = reach.geometry.length\n",
    "    # the procedure is different if the reach is a single line or multiple lines.\n",
    "    # multiple lines can occur if a reach enters and exits a cell more than once\n",
    "    if  reach.geometry.geom_type is 'MultiLineString':\n",
    "        for multi_reach in reach.geometry:\n",
    "            result = ix.intersect(multi_reach)\n",
    "    else:\n",
    "        result = ix.intersect(reach.geometry)\n",
    "    \n",
    "    # put the results of the intersection in a temporary dataframe\n",
    "    df = pd.DataFrame(result)\n",
    "    \n",
    "    # calculate the stage as the mean of the upstream and downstream elevations\n",
    "    cumlen = np.cumsum(df.lengths)\n",
    "    midpoint = cumlen - df.lengths / 2\n",
    "    rise = reach.maxft - reach.minft\n",
    "    grad = rise / reach_len\n",
    "    stage = midpoint * grad\n",
    "    \n",
    "    # add some new fields and append the temporary dataframe to the drain data\n",
    "    df['stage'] = reach.maxft - stage\n",
    "    df['reach'] = index\n",
    "    df['order'] = reach.StreamOrde\n",
    "    df['NHDPlusID'] = reach.NHDPlusID\n",
    "    df['reachcode'] = reach.ReachCode\n",
    "    drains = drains.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T14:57:51.155990Z",
     "start_time": "2021-12-23T14:57:47.667944Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reset the index\n",
    "drains.reset_index(inplace=True)\n",
    "\n",
    "# parse row and col into separate columns\n",
    "drains[['row', 'col']] = pd.DataFrame(drains['cellids'].tolist(), index=drains.index) \n",
    "\n",
    "# convert NHDPlusID to a long integer\n",
    "drains['NHDPlusID'] = drains.NHDPlusID.astype(np.int64)\n",
    "\n",
    "# add a node number based on the left-to-right top-to-bottom sequence number\n",
    "drains['node'] = drains.row * gsm_ncol + drains.col\n",
    "\n",
    "# create a GeoDataFrame of the drain data\n",
    "gdf = gpd.GeoDataFrame(drains, geometry='ixshapes', crs=proj)\n",
    "\n",
    "# drop unused columns\n",
    "gdf.drop(columns=['cellids', 'vertices'], inplace=True)\n",
    "\n",
    "# save to a shapefile\n",
    "gdf.to_file(os.path.join(metadata['gis_dir'], 'drain_segments.shp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create lakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T13:23:11.952803Z",
     "start_time": "2020-07-14T13:23:11.901840Z"
    }
   },
   "source": [
    "Read and intersect waterbody file with domain outline. TODO: Need to look at possible duplication of lake cells and weeding some lakes out by size; maybe as a fraction of the cell size.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T14:58:13.426330Z",
     "start_time": "2021-12-23T14:57:51.156918Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read high resolution NHDPlus waterbodies\n",
    "lakes = gpd.read_file(metadata['vector_name'], layer='NHDWaterbody')\n",
    "lakes.to_crs(crs = proj, inplace=True)\n",
    "\n",
    "# clip waterbodies to the model domain and create an indicator column\n",
    "lake_clip = gpd.overlay(lakes, shp)\n",
    "lake_clip['is_lake'] = 1\n",
    "\n",
    "# save as a shapefile\n",
    "lake_clip.to_file(os.path.join(metadata['gis_dir'], 'lake_clip.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:26:53.172446Z",
     "start_time": "2021-12-23T14:58:13.428232Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start a blank dataframe for lake data\n",
    "lakes = pd.DataFrame()\n",
    "\n",
    "# loop through each waterbody and intersect with the model grid\n",
    "for index, segment in lake_clip.iterrows():\n",
    "    result = ix.intersect(segment.geometry)\n",
    "    # put the results of the intersection in a temporary dataframe\n",
    "    df = pd.DataFrame(result)\n",
    "    # add some new fields and append the temporary dataframe to the drain data\n",
    "    df['segment'] = index\n",
    "    lakes = lakes.append(df)\n",
    "\n",
    "# reset the index\n",
    "lakes.reset_index(inplace=True)\n",
    "\n",
    "# parse row and col into separate columns\n",
    "lakes[['row', 'col']] = pd.DataFrame(lakes['cellids'].tolist(), index=lakes.index) \n",
    "\n",
    "# add a node number based on the left-to-right top-to-bottom sequence number\n",
    "lakes['node'] = lakes.row * gsm_ncol + lakes.col \n",
    "\n",
    "# create a GeoDataFrame of the drain data\n",
    "lakes = gpd.GeoDataFrame(lakes, geometry='ixshapes', crs=proj)\n",
    "\n",
    "# drop unused columns\n",
    "lakes.drop(columns=['cellids', 'vertices'], inplace=True)    \n",
    "\n",
    "# save to a shapefile\n",
    "lakes.to_file(os.path.join(metadata['gis_dir'], 'lake_segments.shp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map drain and lake properties onto the model grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:27:01.029790Z",
     "start_time": "2021-12-23T15:26:53.173735Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a blank dataframe with a row for every model cell in map view (nrow * ncol)\n",
    "model_grid = pd.DataFrame({'node': np.arange(gsm_nrow * gsm_ncol)})\n",
    "\n",
    "# group the drain segments by model cell using node\n",
    "for i, j in drains.groupby('node'):\n",
    "    # if there is more than one segment in a cell, use the most downstream cell (minimum stage)\n",
    "    # multiple segments can occur if a reach enters and exits a cell more than once\n",
    "    index = j.stage.idxmin()\n",
    "    model_grid.loc[i, 'stage'] = j.loc[index, 'stage']\n",
    "    model_grid.loc[i, 'order'] = j.loc[index, 'order']\n",
    "    model_grid.loc[i, 'NHDPlusID'] = j.loc[index, 'NHDPlusID']\n",
    "    model_grid.loc[i, 'reach_len'] = j.lengths.sum()\n",
    "    \n",
    "# group the lake segments by model cell using node\n",
    "# calculate the total area of all waterbodies in each cell \n",
    "for i, j in lakes.groupby('node'):\n",
    "    model_grid.loc[i, 'lake_areas'] = j.areas.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map other spatial data onto model grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add ibound to model grid data frame. Cells whose centers are in the watershed polygon will be active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:27:01.219387Z",
     "start_time": "2021-12-23T15:27:01.030784Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_raster.process_vector_data(metadata['domain_name'], 'ibound')\n",
    "ib = grid_raster.new_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter ibound to eliminate disconnected cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:27:01.235386Z",
     "start_time": "2021-12-23T15:27:01.222380Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Removes isolated active cells from the IBOUND array.\n",
    "# Args: ibound array (nlay, nrow, ncol)\n",
    "# this cell is from Wesley Zell\n",
    "\n",
    "# Distinguish disconnected clusters of active cells in the IBOUND array.\n",
    "# 0 is considered background; in MODLFOW, active cells are != 0.\n",
    "ib[ib != 0] = 1\n",
    "array_of_cluster_idx, num = nd.measurements.label(ib)\n",
    "\n",
    "# Identify the cluster with the most active cells; this is the main active area\n",
    "areas = nd.measurements.sum(ib, array_of_cluster_idx,\\\n",
    "                         index=np.arange(array_of_cluster_idx.max() + 1))\n",
    "max_cluster_idx = np.argmax(areas)\n",
    "\n",
    "# Inactivate all cells that belong to secondary clusters (e.g., islands)\n",
    "ib[array_of_cluster_idx != max_cluster_idx] = 0\n",
    "ib = ib.astype(int)\n",
    "model_grid['ibound'] = ib.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of any data for cells where idomain != 1.  Removes the rows and then add back blank rows so that every top layer cell has a row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:27:01.250334Z",
     "start_time": "2021-12-23T15:27:01.236342Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_grid = model_grid.loc[model_grid.ibound==1, :].reindex(np.arange(gsm_nrow * gsm_ncol))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add vector data to model grid data frame. Any attributes can be added to the modelgrid DataFrame, including alternative data sources.  The connection between modelgrid and the MODFLOW model is made in the next notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:27:01.266353Z",
     "start_time": "2021-12-23T15:27:01.252339Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for src, attribute, name in vector_list:\n",
    "    grid_raster.process_vector_data(src, attribute)\n",
    "    model_grid[name] = grid_raster.new_array.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add raster data to model grid data frame. Any attributes can be added to the modelgrid DataFrame, including alternative data sources.  The connection between modelgrid and the MODFLOW model is made in the next notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:27:08.431496Z",
     "start_time": "2021-12-23T15:27:01.268285Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for src, method, factor, name in raster_list:\n",
    "    grid_raster.process_raster_data(src, method, factor)\n",
    "    model_grid[name] = grid_raster.new_array.ravel() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:27:08.446562Z",
     "start_time": "2021-12-23T15:27:08.432493Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    r_dir = '../gis/recharge'\n",
    "    r_list = os.listdir(r_dir)\n",
    "    \n",
    "    for src in r_list:\n",
    "        src_pth = os.path.join(r_dir, src)\n",
    "        name = '_'.join(src.split('_')[0:2])\n",
    "        if os.path.splitext(src_pth)[-1] == '.tif':\n",
    "            grid_raster.process_raster_data(src_pth, gdal.GRA_Bilinear, 1.0)\n",
    "            model_grid[name] = grid_raster.new_array.ravel()\n",
    "except:\n",
    "    print ('no transient recharge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NHDPlus has a small number of MAXELEVSMO and MINELEVSMO in (mostly?) first order streams that are set to a missing value code -9980. Converted to meters this is -99.80. Replace all such values with the NED value minus 1 (meter). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:27:08.477527Z",
     "start_time": "2021-12-23T15:27:08.448650Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_grid['stage'] = np.where(model_grid.stage == -99.80, model_grid.ned - 1., model_grid.stage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter ibound to make a grid of edge cells. Intersect this with the lake grid. Cell that are on the edge of the model and are in lakes could be treated as GHB cells.  This is very similar to the code above for drain/river cells. FloPy GHB requires a dictionary of lists similar to river/drain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:27:14.822685Z",
     "start_time": "2021-12-23T15:27:08.483393Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# In case there is more than one polygon in the domain file (but there shouldn't be), \n",
    "# find the one with the largest area. Extract the boundary LineString of the polygon.\n",
    "poly = max(shp.geometry, default=shp.geometry[0], key=lambda a: a.area).boundary\n",
    "\n",
    "edge_nodes = []\n",
    "\n",
    "# loop through rows and columns, find the cell center, intersect it with\n",
    "# the polygon gon boundary.  If the intersection is True, append it to a list,\n",
    "# otherwise append False)\n",
    "for i in range(ml.nrow):\n",
    "    for j in range(ml.ncol):\n",
    "        xy = ml.get_cell_vertices(i, j)\n",
    "        p = Polygon(xy)\n",
    "        edge_nodes.append(p.intersects(poly))\n",
    "\n",
    "model_grid['edge'] = edge_nodes\n",
    "\n",
    "ghb = (model_grid.edge & model_grid.lake_areas.notnull())\n",
    "ghb = ghb.astype(int)\n",
    "model_grid['ghb'] = ghb.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GHB is used for marine boundaries along cells where the elevation or river stage is < sea level. Added by Janet Barclay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:27:14.838672Z",
     "start_time": "2021-12-23T15:27:14.825678Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sea_level = 0\n",
    "den_salt = 1.2\n",
    "den_fresh = 1.0\n",
    "river_depth = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:27:14.868564Z",
     "start_time": "2021-12-23T15:27:14.841635Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_grid['ghb_sea'] = 0\n",
    "# setting the ghb for land surface below sea level\n",
    "model_grid.loc[model_grid['ned'] <= sea_level, 'ghb_sea'] = 1\n",
    "\n",
    "# convert the depth of saltwater to a freshwater head using the depth and the densities of each\n",
    "# fresh_head = (den_sea / den_fresh)*sea_level - [(den_sea - den_fresh)/den_fresh]*depth_sea\n",
    "model_grid['fresh_head'] = (den_salt / den_fresh) * sea_level - \\\n",
    "    ((den_salt - den_fresh) / den_fresh) * (sea_level - model_grid['ned'])\n",
    "\n",
    "# changing rivers with stage < sea level to ghb\n",
    "model_grid.loc[(model_grid['stage'] < sea_level) &\n",
    "               (model_grid.stage > -9990), 'ghb_sea'] = 1\n",
    "model_grid.loc[(model_grid['stage'] < sea_level) & (model_grid.stage > -9990), 'fresh_head'] = (den_salt / den_fresh) * sea_level - \\\n",
    "    ((den_salt - den_fresh) / den_fresh) * (sea_level -\n",
    "                                      (model_grid.loc[(model_grid['stage'] < sea_level) & (model_grid.stage > -9990), 'stage'] - river_depth))\n",
    "\n",
    "# change the stage to np.nan to avoid adding a drain as well\n",
    "model_grid.loc[(model_grid['stage'] < sea_level) & (\n",
    "    model_grid.stage > -9990), 'stage'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace grid-cell-mean NED elevations with interpolated stream stage, but only in model cells that contain a stream. The resulting data is called 'top'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:27:14.884576Z",
     "start_time": "2021-12-23T15:27:14.871035Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_grid['top'] = model_grid.ned\n",
    "index = model_grid.stage.notnull()\n",
    "model_grid.loc[index, 'top'] = model_grid.stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace grid-cell mean NED elevations with fresh head for ghb cells with top above fresh head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:27:14.899719Z",
     "start_time": "2021-12-23T15:27:14.886515Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index = (model_grid.ghb_sea == 1) & (model_grid.fresh_head < model_grid.top)\n",
    "model_grid.loc[index, 'top'] = model_grid.fresh_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add observation type to cells.  \"hydro\" if a perennial stream, \"topo\" everywhere else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:27:14.930904Z",
     "start_time": "2021-12-23T15:27:14.901477Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "is_active = model_grid.ibound != 0\n",
    "# is_intermit = model_grid.intermit == True\n",
    "is_sea = model_grid.ghb_sea == 1\n",
    "# marine cells (those with ghb_sea boundary) are included as hydro observations\n",
    "hydro_index = model_grid.stage.notnull() | is_sea\n",
    "\n",
    "is_hydro_obs = is_active & hydro_index# & ~is_intermit\n",
    "is_topo_obs = is_active & ~is_hydro_obs & ~is_sea\n",
    "\n",
    "model_grid['obs_type'] = np.nan\n",
    "model_grid.loc[is_hydro_obs, 'obs_type'] = 1\n",
    "model_grid.loc[is_topo_obs, 'obs_type'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through all the columns in model_grid and write a GeoTiff of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:27:15.274071Z",
     "start_time": "2021-12-23T15:27:14.933305Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for column, item in model_grid.iteritems():\n",
    "    fname = '{}.tif'.format(column)\n",
    "#     dst = os.path.join(model_ws, fname)\n",
    "#     if os.path.exists(dst):\n",
    "#         os.remove(dst)\n",
    "    data = item.values.reshape(gsm_nrow, gsm_ncol)\n",
    "    grid_raster.new_array = data\n",
    "    dst = os.path.join(metadata['gis_dir'], '{}.tif'.format(column))\n",
    "    grid_raster.write_raster(dst, which_raster='new')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add some additional columns to `model_grid` and write it to model_grid.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:27:15.288977Z",
     "start_time": "2021-12-23T15:27:15.276012Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_grid.loc[is_hydro_obs, 'obs_type'] = 'hydro'\n",
    "model_grid.loc[is_topo_obs, 'obs_type'] = 'topo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:27:15.304965Z",
     "start_time": "2021-12-23T15:27:15.290973Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lays, rows, cols = np.indices((1, gsm_nrow, gsm_ncol))\n",
    "\n",
    "model_grid['lay'] = lays.ravel()\n",
    "model_grid['row'] = rows.ravel()\n",
    "model_grid['col'] = cols.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map stream order to a stream width using data from Downing et al, 2012. Order is the Strahler order and width is the trapezoidal width in meters.\n",
    "\n",
    "J.A. Downing, J.J. Cole, C.M. Duarte, J.J. Middelburg, J.M. Melack, Y.T.\n",
    "Prairie, P. Kortelainen, R.G. Striegl, W.H. McDowell & L.J. Tranvik (2012) Global abundance and\n",
    "size distribution of streams and rivers, Inland Waters, 2:4, 229-236, DOI: 10.5268/IW-2.4.502"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:27:15.320949Z",
     "start_time": "2021-12-23T15:27:15.307019Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "width_table = np.array([(1, 0.8),\n",
    "(2, 1.8),\n",
    "(3, 3.7),\n",
    "(4, 8.3),\n",
    "(5, 29.3),\n",
    "(6, 73.3),\n",
    "(7, 131.5),\n",
    "(8, 264.5),\n",
    "(9, 608.5),\n",
    "(10, 988.5),\n",
    "(11, 803.0),\n",
    "(12, 3079.0)], dtype=[('order', '<i8'), ('width', '<f8')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:27:15.336120Z",
     "start_time": "2021-12-23T15:27:15.322887Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# map stream order to stream width based on Downing (2012)\n",
    "model_grid['width'] = model_grid['order'].replace(\n",
    "    width_table['width'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:27:15.366997Z",
     "start_time": "2021-12-23T15:27:15.339738Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_gridlines = np.linspace(gsm_x0, gsm_xm, gsm_ncol + 1)\n",
    "y_gridlines = np.linspace(gsm_y0, gsm_ym, gsm_nrow + 1)\n",
    "\n",
    "model_grid['xvert_l'] = np.tile(x_gridlines[:-1], gsm_nrow)\n",
    "model_grid['xvert_r'] = np.tile(x_gridlines[1:], gsm_nrow)\n",
    "model_grid['yvert_t'] = np.repeat(y_gridlines[:-1], gsm_ncol)\n",
    "model_grid['yvert_b'] = np.repeat(y_gridlines[1:], gsm_ncol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:27:15.915854Z",
     "start_time": "2021-12-23T15:27:15.368976Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_grid.to_csv(os.path.join(metadata['gis_dir'], 'model_grid.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot domain outline, model grid, and drainage network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T17:21:21.036828Z",
     "start_time": "2021-12-28T17:21:20.305642Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = grid_raster.plot_raster(sk={'figsize': (11, 8.5)})\n",
    "\n",
    "dum = nhd_clip.plot(ax=ax, linewidth=0.75)\n",
    "dum = shp.plot(ax=ax, color='red', alpha=0.3)\n",
    "dum = box.plot(ax=ax, color='none', edgecolor='k', linewidth=2)\n",
    "dum = ax.vlines(x_gridlines, gsm_y0, gsm_ym, linewidth=0.5, alpha=0.5)\n",
    "dum = ax.hlines(y_gridlines, gsm_x0, gsm_xm, linewidth=0.5, alpha=0.5)\n",
    "\n",
    "fig.set_tight_layout(True)\n",
    "plt.savefig('model_grid.png')\n",
    "\n",
    "i = Image(filename='model_grid.png')\n",
    "i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "state": {
    "fe74db59d5304861a6075ed48715a1d7": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
