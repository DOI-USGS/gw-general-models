{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a General Simulation Model from a model_grid.csv and ibound.tif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:28:33.325585Z",
     "start_time": "2021-12-23T15:28:30.828640Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import os\n",
    "import datetime as dt\n",
    "import pickle, joblib\n",
    "\n",
    "\n",
    "# Standard data science libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import scipy.optimize as so \n",
    "import scipy.interpolate as si\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-notebook')\n",
    "\n",
    "# Options for pandas\n",
    "pd.options.display.max_columns = 20\n",
    "pd.options.display.max_rows = 50\n",
    "\n",
    "# Display all cell outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import Math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Package imports specific to this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:28:34.307127Z",
     "start_time": "2021-12-23T15:28:33.328428Z"
    }
   },
   "outputs": [],
   "source": [
    "import flopy as fp\n",
    "import shutil\n",
    "import Genmod_Utilities as gmu\n",
    "import RTD_util6 as rtd_ut\n",
    "from matplotlib import colors\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from argparse import Namespace\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set scenario specific model values and map hydrologic properties to columns in `model_grid`. \n",
    "\n",
    "These values are stored in a Python dictionary and saved for use in later notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **num_surf_layers** : int, number of surficial (unconsolidated) aquifer layers\n",
    "\n",
    "**Note that there should be at least 2 bedrock layers for the interpolation used in this method to work**\n",
    "\n",
    "* **num_bdrk_layers** : int, number of bedrock layers\n",
    "* **K_surf**: str, column in `model_grid` to map to surficial hydraulic conductivity\n",
    "* **K_bdrk**: str, column in `model_grid` to map to bedrock hydraulic conductivity\n",
    "* **ibound**: str, column in `model_grid` to map to idomain\n",
    "* **GHB** : bool, whether to include general head boundary in lake cells on the model boundary\n",
    "* **GHB_sea** : bool, whether to correct head at general head boundary for density\n",
    "* **K_lakes** : float, hydraulic conductivity to set for bodies of open water (for example, lakes)\n",
    "* **k33overk** : float, ratio of vertical to horizontal hydraulic conductivity\n",
    "* **min_thk** : float, minimum thickness for the sum of all surficial layers\n",
    "* **stream_bed_thk** : float, thickness of streambed used in calculating conductance\n",
    "* **bedrock_thk** : float, thickness of bedrock\n",
    "* **stream_bed_kadjust** : float, fraction of cell hydraulic conductivity used to calculate conductance in streams\n",
    "* **coastal_sed_thk** : float, thickness of coastal sediments used in calculating conductance in coastal GHB\n",
    "* **coastal_sed_kadjust** : float, fraction of cell hydraulic conductivity used to calculate conductance in coastal GHB\n",
    "* **sea_level** : float, mean annual sea level\n",
    "* **den_salt** : float, density of salt water\n",
    "* **den_fresh** : float, density of fresh water\n",
    "* **NPER** : int, number of stress periods\n",
    "* **err_tol** : float, watertable elevation +/- err_tol is used to compute the objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:28:34.463620Z",
     "start_time": "2021-12-23T15:28:34.449087Z"
    }
   },
   "outputs": [],
   "source": [
    "gsm_metadata = dict(\n",
    "num_surf_layers = 2,\n",
    "num_bdrk_layers = 3,\n",
    "K_surf = 'surf_K',\n",
    "K_bdrk = 'bed_K',\n",
    "ibound = 'ibound',\n",
    "GHB = True,\n",
    "GHB_sea = False,\n",
    "K_lakes = 3000.,\n",
    "k33overk = 0.1,\n",
    "min_thk = 3.,\n",
    "stream_bed_thk = 0.3,\n",
    "surf_thk = 'thickness_Shang', \n",
    "bedrock_thk = 100.,\n",
    "stream_bed_kadjust = 1.0,\n",
    "coastal_sed_thk = 1.5,\n",
    "coastal_sed_kadjust = 15.,\n",
    "sea_level = 0 ,\n",
    "den_salt = 1022 ,\n",
    "den_fresh = 1000 ,\n",
    "NPER = 1,\n",
    "err_tol = 1.\n",
    ")\n",
    "\n",
    "dst = os.path.join('model_ws', 'gsm_metadata.json')\n",
    "with open(dst, 'w') as f:\n",
    "    json.dump(gsm_metadata, f, indent=4)   \n",
    "    \n",
    "meta = Namespace(**gsm_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:28:34.323083Z",
     "start_time": "2021-12-23T15:28:34.309066Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('GenMod_metadata.txt') as json_file:\n",
    "    metadata = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model workspace directory `model_ws`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:28:34.368220Z",
     "start_time": "2021-12-23T15:28:34.325023Z"
    }
   },
   "outputs": [],
   "source": [
    "if os.path.exists('model_ws'):\n",
    "    shutil.rmtree('model_ws')\n",
    "    os.makedirs('model_ws')\n",
    "else:\n",
    "    os.makedirs('model_ws')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read `model_grid.csv` that was created in the first notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:28:34.448255Z",
     "start_time": "2021-12-23T15:28:34.371199Z"
    }
   },
   "outputs": [],
   "source": [
    "model_file = os.path.join(metadata['gis_dir'], 'model_grid.csv')\n",
    "model_grid = pd.read_csv(model_file)\n",
    "model_grid.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:28:34.479062Z",
     "start_time": "2021-12-23T15:28:34.466040Z"
    }
   },
   "outputs": [],
   "source": [
    "model_grid.loc[model_grid[meta.K_bdrk] == 0, meta.ibound] = 0\n",
    "model_grid.loc[model_grid[meta.K_surf] == 0, meta.ibound] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map `model_grid` (created with Notebook 1) to MODFLOW6 arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:28:34.571775Z",
     "start_time": "2021-12-23T15:28:34.481998Z"
    }
   },
   "outputs": [],
   "source": [
    "grid = os.path.join(metadata['gis_dir'], 'ibound.tif')\n",
    "grid_raster = gmu.SourceProcessing(np.nan)\n",
    "grid_raster.read_raster(grid)\n",
    "\n",
    "NROW = grid_raster.nrow\n",
    "NCOL = grid_raster.ncol\n",
    "num_cells = NROW * NCOL\n",
    "\n",
    "delr = np.abs(grid_raster.gt[1])\n",
    "delc = np.abs(grid_raster.gt[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model grid geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:28:34.587764Z",
     "start_time": "2021-12-23T15:28:34.574965Z"
    }
   },
   "outputs": [],
   "source": [
    "ibound = model_grid[meta.ibound].values.reshape(NROW, NCOL)\n",
    "inactive = (ibound == 0)\n",
    "top = model_grid.top.values.reshape(NROW, NCOL)\n",
    "thick = model_grid.thickness_Shang.values.reshape(NROW, NCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K for surficial and bedrock units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:28:34.603664Z",
     "start_time": "2021-12-23T15:28:34.589702Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "surf_k = model_grid[meta.K_surf].values.reshape(NROW, NCOL) \n",
    "bdrk_k = model_grid[meta.K_bdrk].values.reshape(NROW, NCOL) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process boundary condition information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:28:34.619622Z",
     "start_time": "2021-12-23T15:28:34.605660Z"
    }
   },
   "outputs": [],
   "source": [
    "recharge = model_grid.recharge.values.reshape(NROW, NCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drains\n",
    "\n",
    "Create a dictionary of stream information for the drain or river package.\n",
    "River package input also needs the elevation of the river bed. Don't use both packages. The choice is made by commenting/uncommenting sections of the modflow function. Replace segment_len (segment length) with the conductance. The river package has not been tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:28:34.666967Z",
     "start_time": "2021-12-23T15:28:34.621617Z"
    }
   },
   "outputs": [],
   "source": [
    "drn_data = model_grid[(model_grid.order != 0) &\n",
    "                      (model_grid.ibound == 1)].copy()\n",
    "\n",
    "# adjust streambed K based on cell K and stream_bed_kadjust\n",
    "drn_data['dcond'] = drn_data[meta.K_surf] * meta.stream_bed_kadjust * \\\n",
    "    drn_data.reach_len * drn_data.width / meta.stream_bed_thk \n",
    "drn_data['iface'] = 6\n",
    "\n",
    "drn_data = drn_data.reindex(\n",
    "    ['lay', 'row', 'col', 'stage', 'dcond', 'iface'], axis=1)\n",
    "drn_data.rename(columns={'lay': 'k', 'row': 'i',\n",
    "                         'col': 'j', 'stage': 'stage'}, inplace=True)\n",
    "\n",
    "drn_data = drn_data[drn_data.dcond > 0]\n",
    "\n",
    "# Convert to MODFLOW6 format\n",
    "cellid = list(zip(drn_data.k, drn_data.i, drn_data.j))\n",
    "drn_data6 = pd.DataFrame({'cellid': cellid, 'stage': drn_data.stage, 'dcond': drn_data.dcond, 'iface': drn_data.iface})\n",
    "drn_recarray6 = drn_data6.to_records(index=False)\n",
    "drn_dict6 = {0 : drn_recarray6}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General head boundary (GHB)\n",
    "\n",
    "Create a dictionary of information for the general-head boundary package.\n",
    "Similar to the above cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:28:34.698466Z",
     "start_time": "2021-12-23T15:28:34.669560Z"
    }
   },
   "outputs": [],
   "source": [
    "if (model_grid.ghb_sea.sum() > 0) & meta.GHB:\n",
    "    ghb_flag = model_grid.ghb == 1\n",
    "    ghb_data = model_grid.loc[ghb_flag, :].copy()\n",
    "    ghb_data['cond'] = ghb_data[meta.K_surf] * delc * delr / meta.stream_bed_thk\n",
    "    ghb_data['iface'] = 6\n",
    "\n",
    "    ghb_data = ghb_data.reindex(['lay', 'row', 'col', 'ned', 'cond', 'iface'], axis=1)\n",
    "\n",
    "    ghb_data.rename(columns={'lay': 'k', 'row': 'i', 'col': 'j', 'ned': 'stage'}, inplace=True)\n",
    "    \n",
    "    ghb_data.dropna(axis='index', inplace=True)\n",
    "    ghb_recarray = ghb_data.to_records(index=False)\n",
    "    ghb_dict = {0 : ghb_recarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marine general head boundary\n",
    "\n",
    "Create a dictionary for the marine general-head boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:28:34.714370Z",
     "start_time": "2021-12-23T15:28:34.700420Z"
    }
   },
   "outputs": [],
   "source": [
    "# if model_grid.ghb_sea.sum() > 0:\n",
    "#     #currently the marine ghb would overwrite any existing ghb, therefore write an alert\n",
    "#     if GHB & GHB_sea:\n",
    "#         GHB = False\n",
    "#         print(\"Code doesn't support multiple ghb's. Marine ghb will be implemented.\")    \n",
    "#     ghb_flag = model_grid.ghb_sea == 1\n",
    "#     ghb_sea_data = model_grid.loc[ghb_flag, ['lay', 'row', 'col', 'fresh_head', 'segment_len', meta.K_surf]]\n",
    "#     ghb_sea_data.columns = ['k', 'i', 'j', 'stage', 'segment_len', meta.K_surf]\n",
    "#     gcond = ghb_sea_data[meeta.K_surf] * L * L / coastal_sed_thk / coastal_sed_kadjust\n",
    "#     ghb_sea_data['segment_len'] = gcond\n",
    "#     ghb_sea_data.rename(columns={'segment_len' : 'cond'}, inplace=True)\n",
    "#     ghb_sea_data.drop(meta.K_surf, axis=1, inplace=True)\n",
    "#     ghb_sea_data.dropna(axis='index', inplace=True)\n",
    "#     ghb_sea_data.insert(ghb_sea_data.shape[1], 'iface', 6)\n",
    "#     ghb_sea_recarray = ghb_sea_data.to_records(index=False)\n",
    "#     ghb_sea_dict = {0 : ghb_sea_recarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 1-layer model to get initial top-of-aquifer on which to drape subsequent layering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get starting heads from top elevations. The top is defined as the model-cell-mean NED elevation except in streams, where it is interpolated between MaxElevSmo and MinElevSmo in the NHD (called 'stage' in model_grid). Make them a little higher than land so that drains don't accidentally go dry too soon.\n",
    "\n",
    "Modify the bedrock surface, ensuring that it is always at least min_thk below the top elevation. This calculation will be revisited for the multi-layer case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a function to create and run MODFLOW6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:28:34.745796Z",
     "start_time": "2021-12-23T15:28:34.716365Z"
    }
   },
   "outputs": [],
   "source": [
    "def modflow(md, mfpth6, model_ws, nlay=1, top=top, strt=top, nrow=NROW, ncol=NCOL, botm=(top - thick),\n",
    "            ibound=ibound, hk=surf_k, rech=recharge, stream_dict=drn_dict6, delr=delr, delc=delc,\n",
    "            hnoflo=-9999., hdry=-8888., iphdry=1, vani=meta.k33overk):\n",
    "\n",
    "    # Create the Flopy simulation object\n",
    "    sim = fp.mf6.MFSimulation(sim_name=md, exe_name=mfpth6,\n",
    "                              version='mf6', sim_ws=model_ws)\n",
    "\n",
    "    # Create the Flopy temporal discretization object\n",
    "    tdis = fp.mf6.modflow.mftdis.ModflowTdis(sim, pname='tdis', time_units='DAYS',\n",
    "                                             nper=1, perioddata=[(1.0E+05, 1, 1.0)])\n",
    "\n",
    "    # Create the Flopy groundwater flow (gwf) model object\n",
    "    model_nam_file = '{}.nam'.format(md)\n",
    "    gwf = fp.mf6.ModflowGwf(sim, modelname=md, newtonoptions='UNDER_RELAXATION', \n",
    "                            model_nam_file=model_nam_file, save_flows=True)\n",
    "\n",
    "    # Create the Flopy iterative model solver (ims) Package object\n",
    "    ims = fp.mf6.modflow.mfims.ModflowIms(\n",
    "        sim, pname='ims', complexity='COMPLEX')\n",
    "\n",
    "    # Create the discretization package\n",
    "    dis = fp.mf6.modflow.mfgwfdis.ModflowGwfdis(gwf, pname='dis', nlay=nlay, nrow=NROW, ncol=NCOL, length_units='METERS',\n",
    "                                                delr=delr, delc=delc, top=top, botm=botm, idomain=ibound)\n",
    "\n",
    "    # Create the initial conditions package\n",
    "    ic = fp.mf6.modflow.mfgwfic.ModflowGwfic(gwf, pname='ic', strt=strt)\n",
    "\n",
    "    # Create the node property flow package\n",
    "    npf = fp.mf6.modflow.mfgwfnpf.ModflowGwfnpf(gwf, pname='npf', icelltype=1, k=hk, k33=vani,\n",
    "                                                k33overk=True, save_flows=True)\n",
    "\n",
    "    rch = fp.mf6.modflow.mfgwfrcha.ModflowGwfrcha(\n",
    "        gwf, recharge=rech, save_flows=True)\n",
    "\n",
    "    drn = fp.mf6.modflow.mfgwfdrn.ModflowGwfdrn(\n",
    "        gwf, stress_period_data=drn_dict6, save_flows=True)\n",
    "\n",
    "    # Create the output control package\n",
    "    headfile = '{}.hds'.format(md)\n",
    "    head_filerecord = [headfile]\n",
    "    budgetfile = '{}.cbb'.format(md)\n",
    "    budget_filerecord = [budgetfile]\n",
    "    saverecord = [('HEAD', 'ALL'),\n",
    "                  ('BUDGET', 'ALL')]\n",
    "    printrecord = [('HEAD', 'LAST')]\n",
    "    \n",
    "    oc = fp.mf6.modflow.mfgwfoc.ModflowGwfoc(gwf, pname='oc', saverecord=saverecord,\n",
    "                                             head_filerecord=head_filerecord,\n",
    "                                             budget_filerecord=budget_filerecord,\n",
    "                                             printrecord=None)\n",
    "\n",
    "    # Write the datasets\n",
    "    sim.write_simulation(silent=False)\n",
    "\n",
    "    # Run the simulation\n",
    "    success, buff = sim.run_simulation(silent=False)\n",
    "    \n",
    "    if success:\n",
    "        print('\\nSuccess is sweet')\n",
    "        print(\"    Your {:0d} layer model ran successfully\\n\\n\".format(nlay))\n",
    "    else:\n",
    "        print('\\nThat sucks')\n",
    "        print(\"    Your {:0d} layer model didn't converge\\n\\n\".format(nlay))\n",
    "\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run 1-layer MODFLOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function to run MODFLOW for 1 layer to getting approximate top-of-aquifer elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:28:36.459448Z",
     "start_time": "2021-12-23T15:28:34.748236Z"
    }
   },
   "outputs": [],
   "source": [
    "sim = modflow(metadata['HUC8_name'], metadata['modflow_path'], 'model_ws', nlay=1, top=top * 1.2, strt=top * 1.05, nrow=NROW, ncol=NCOL, botm=(top - thick - meta.bedrock_thk),\n",
    "              ibound=ibound, hk=surf_k, rech=recharge, stream_dict=drn_dict6, delr=delr, delc=delc, iphdry=0, vani=meta.k33overk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the head file and calculate new layer top (wt) and bottom (bot) elevations based on the estimated\n",
    "water table (wt) being the top of the top layer. Divide the surficial layer into NLAY equally thick layers between wt and the bedrock surface elevation (as computed using minimum surficial thickness). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make new model with (possibly) multiple layers. If there are dry cells in the 1 layer model, they are converted to NaN (not a number). The minimum function in the first line returns NaN if the element of either input arrays is NaN.  In that case, replace NaN in modeltop with the top elevation. The process is similar to the 1 layer case. Thickness is estimated based on modeltop and bedrock and is constrained to be at least min_thk (set in gen_mod_dict.py). This thickness is divided into num_surf_layers number of layers. The cumulative thickness of these layers is the distance from the top of the model to the bottom of the layers. This 3D array of distances (the same for each layer) is subtracted from modeltop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the estimated water table as the new top-of-aquifer elevations sometimes leads to the situation, in usually a very small number of cells, that the drain elevation is below the bottom of the cell.  The following procedure resets the bottom elevation to one meter below the drain elevation if that is the case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If add_bedrock = True in gen_mod_dict.py, add a layer to the bottom and increment NLAY by 1.\n",
    "* Assign the new bottom-most layer an elevation equal to the elevation of the bottom of the lowest surficial layer minus bedrock_thk, which is specified in rock_riv_dict (in gen_mod_dict.py).\n",
    "* Concatenate the new bottom-of-bedrock-layer to the bottom of the surficial bottom array.\n",
    "* Compute the vertical midpoint of each cell. Make an array (bedrock_index) that is True if the bedrock surface is higher than the midpoint and False if it is not.\n",
    "* lay_extrude replaces the old lay_extrude to account for the new bedrock layer. It is not used in this cell, but is used later to extrude other arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrude all arrays to NLAY number of layers. Create a top-of-aquifer elevation (fake_top) that is higher (20% in this case) than the simulated 1-layer water table because in doing this approximation, some stream elevations end up higher than top_of_aquifer and thus do not operate as drains. The fake_top shouldn't affect model computations if it is set high enough because the model uses convertible (confined or unconfined) layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run MODFLOW again using the new layer definitions.  The difference from the first run is that the top-of-aquifer elevation is the 1-layer water table rather than land surface, and of course, the number of surficial layers and/or the presence of a bedrock layer is different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:28:46.789401Z",
     "start_time": "2021-12-23T15:28:36.461442Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    rtd = rtd_ut.RTD_util(sim, 'flow', 'rt')\n",
    "    rtd.get_watertable()\n",
    "    wt = np.ma.masked_invalid(rtd.water_table)\n",
    "\n",
    "    top_layer1 = np.minimum(wt, top)\n",
    "    bedrock_top = top - thick\n",
    "    thk = np.maximum(top_layer1 - bedrock_top, meta.min_thk)\n",
    "    \n",
    "    NLAY = meta.num_surf_layers + meta.num_bdrk_layers\n",
    "    \n",
    "    lay_extrude = np.ones((meta.num_surf_layers, NROW, NCOL))\n",
    "    \n",
    "    surf_thk = lay_extrude * thk / meta.num_surf_layers\n",
    "    surf_elev_array = top_layer1 - np.cumsum(surf_thk, axis=0)\n",
    "    surf_k_array = lay_extrude * surf_k\n",
    "\n",
    "    lay_extrude = np.ones((meta.num_bdrk_layers, NROW, NCOL))\n",
    "    \n",
    "    bdrk_thk = lay_extrude * meta.bedrock_thk / meta.num_bdrk_layers\n",
    "    bdrk_elev_array = surf_elev_array[-1, ...] - np.cumsum(bdrk_thk, axis=0)\n",
    "    bdrk_k_array = lay_extrude * bdrk_k\n",
    "    \n",
    "    botm_array = np.vstack((surf_elev_array, bdrk_elev_array))\n",
    "    lay_thk = np.vstack((surf_thk, bdrk_thk))\n",
    "    hk_3d = np.vstack((surf_k_array, bdrk_k_array))\n",
    "\n",
    "    lay_extrude = np.ones((NLAY, NROW, NCOL))\n",
    "    stg = model_grid.stage.copy()\n",
    "    stg[model_grid.order == 0] = 1.E+30\n",
    "    tmpdrn = (lay_extrude * stg.values.reshape(NROW, NCOL)).ravel()\n",
    "    tmpbot = botm_array.ravel()\n",
    "    index = np.less(tmpdrn, tmpbot)\n",
    "    tmpbot[index] = tmpdrn[index] - 1.0\n",
    "    botm_array = tmpbot.reshape(NLAY, NROW, NCOL)\n",
    "\n",
    "    mids = botm_array + lay_thk / 2\n",
    "    bedrock_index = mids < bedrock_top\n",
    "\n",
    "    la = model_grid.lake_areas.values.reshape(NROW, NCOL)\n",
    "    \n",
    "    # new way to calculate lake K\n",
    "    frac_area = la / delr / delc\n",
    "    hk_3d[0, ...] =  hk_3d[0, ...] * (1 - frac_area) +  meta.K_lakes * frac_area\n",
    "    \n",
    "    # next line is the original way to calculate lake K\n",
    "#     hk_3d[0, la == 1] = K_lakes\n",
    "\n",
    "    hk_3d[bedrock_index] = (lay_extrude * bdrk_k).astype(np.float32)[bedrock_index]\n",
    "    \n",
    "    ind = distance_transform_edt(hk_3d==0, return_distances=False, return_indices=True)\n",
    "    hk_3d = hk_3d[tuple(ind)]\n",
    "\n",
    "    strt_3d = (lay_extrude * top_layer1.data * 1.05).astype(np.float32)\n",
    "    ibound_3d = (lay_extrude * ibound).astype(np.int16)\n",
    " \n",
    "    dst = os.path.join('bedrock_flag_array.npz')\n",
    "    np.savez(dst, bedrock_index=bedrock_index)\n",
    "\n",
    "    sim = modflow(metadata['HUC8_name'], metadata['modflow_path'], 'model_ws', nlay=NLAY, top=top_layer1.data, strt=strt_3d, nrow=NROW, ncol=NCOL, \n",
    "            botm=botm_array, ibound=ibound_3d, hk=hk_3d, rech=recharge, stream_dict=drn_dict6, delr=delr, \n",
    "            delc=delc, hnoflo=-9999., hdry=-8888., iphdry=1, vani=meta.k33overk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the new head array and save it to a GeoTiff file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T17:42:57.745727Z",
     "start_time": "2021-12-28T17:42:57.512519Z"
    }
   },
   "outputs": [],
   "source": [
    "rtd = rtd_ut.RTD_util(sim, 'flow', 'rt')\n",
    "rtd.get_watertable()\n",
    "water_table = rtd.water_table\n",
    "\n",
    "water_table[water_table > (2 * model_grid.ned.max())] = np.nan\n",
    "grid_raster.new_array = water_table\n",
    "\n",
    "fig, ax = grid_raster.plot_raster(which_raster='new', sk={'figsize': (11, 8.5)})\n",
    "fig.set_tight_layout(True)\n",
    "dst = os.path.join('precal-heads.png')\n",
    "\n",
    "plt.savefig(dst)\n",
    "\n",
    "i = Image(filename='precal-heads.png')\n",
    "i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute model errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:28:46.991352Z",
     "start_time": "2021-12-23T15:28:46.962416Z"
    }
   },
   "outputs": [],
   "source": [
    "dif_wt = 1\n",
    "hyd_wt = 1\n",
    "\n",
    "t_crit = (model_grid.obs_type =='topo') & (ibound.ravel() != 0)\n",
    "topo_cells = t_crit.values.reshape(NROW, NCOL)\n",
    "\n",
    "h_crit = (model_grid.obs_type =='hydro') & (ibound.ravel() != 0)\n",
    "hydro_cells = h_crit.values.reshape(NROW, NCOL)\n",
    "\n",
    "num_topo = np.count_nonzero(topo_cells)\n",
    "num_hydro = np.count_nonzero(hydro_cells)\n",
    "\n",
    "topo = (top + meta.err_tol) < water_table\n",
    "hydro = (top - meta.err_tol) > water_table\n",
    "\n",
    "topo_error = topo & topo_cells\n",
    "hydro_error = hydro & hydro_cells\n",
    "\n",
    "t = np.count_nonzero(topo_error)\n",
    "h = np.count_nonzero(hydro_error)\n",
    "\n",
    "topo_rate = t / num_topo\n",
    "hydro_rate = h / num_hydro\n",
    "\n",
    "edif = dif_wt * np.abs(topo_rate - hydro_rate)\n",
    "esum = topo_rate + hyd_wt * hydro_rate\n",
    "target = -(edif + esum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a cross-section to see what the layers look like.  Change row_to_plot to see other rows.  Columns could be easily added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T17:51:56.481215Z",
     "start_time": "2021-12-28T17:51:56.270082Z"
    }
   },
   "outputs": [],
   "source": [
    "def ma2(data2D):\n",
    "    return np.ma.MaskedArray(data2D, mask=inactive)\n",
    "\n",
    "\n",
    "def ma3(data3D):\n",
    "    return np.ma.MaskedArray(data3D, mask=(ibound_3d == 0))\n",
    "\n",
    "\n",
    "def interpolate_travel_times(points, values, xi):\n",
    "    return si.griddata(points, values, xi, method='linear')\n",
    "\n",
    "\n",
    "def plot_travel_times(ax, x, y, tt, shp):\n",
    "    with np.errstate(invalid='ignore'):\n",
    "        return ax.contourf(x.reshape(shp), y.reshape(shp), tt[:].reshape(shp),\n",
    "                           colors=colors, alpha=1.0, levels=levels, antialiased=True)\n",
    "\n",
    "\n",
    "row_to_plot = np.int32(NROW / 2)\n",
    "# row_to_plot = 65\n",
    "xplot = np.linspace(delc / 2, NCOL * delc - delc / 2, NCOL)\n",
    "\n",
    "mKh = ma3(hk_3d)\n",
    "mtop = ma2(top)\n",
    "mbed = ma2(bedrock_top)\n",
    "mbot = ma3(botm_array)\n",
    "\n",
    "# lay_colors = ['green', 'red', 'gray']\n",
    "# make a color map of fixed colors\n",
    "cmap = plt.cm.coolwarm\n",
    "bounds = [0, 5, 10]\n",
    "norm = colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "fig = plt.figure(figsize=(11, 8.5))\n",
    "\n",
    "ax1 = plt.subplot2grid((4, 1), (0, 0), rowspan=3)\n",
    "\n",
    "dum = ax1.plot(xplot, mtop[row_to_plot, ],\n",
    "               label='land surface', color='black', lw=0.5)\n",
    "dum = ax1.plot(xplot, rtd.water_table[row_to_plot, ],\n",
    "               label='water table', color='blue', lw=1.)\n",
    "dum = ax1.fill_between(xplot, mtop[row_to_plot, ], mbot[0, row_to_plot, :], alpha=0.25,\n",
    "                       color='blue', lw=0.75)\n",
    "for lay in range(NLAY-1):\n",
    "    label = 'layer {}'.format(lay+2)\n",
    "    dum = ax1.fill_between(xplot, mbot[lay, row_to_plot, :], mbot[lay+1, row_to_plot, :],\n",
    "                           color=cmap(lay / NLAY), alpha=0.50, lw=0.75)\n",
    "dum = ax1.plot(xplot, mbed[row_to_plot, :], label='bedrock',\n",
    "               color='red', linestyle='dotted', lw=1.5)\n",
    "dum = ax1.plot(xplot, mbot[-1, row_to_plot, :], color='black',\n",
    "               linestyle='dashed', lw=0.5, label='model bottom')\n",
    "\n",
    "# , bbox_to_anchor=(1.0, 0.5))\n",
    "dum = ax1.legend(loc=0, frameon=False, fontsize=10, ncol=1)\n",
    "dum = ax1.set_ylabel('Altitude, in meters')\n",
    "# dum = ax1.set_xticklabels('')\n",
    "dum = ax1.set_title('Section along row {}'.format(row_to_plot))\n",
    "\n",
    "# ax2 = plt.subplot2grid((4, 1), (3, 0))\n",
    "# dum = ax2.fill_between(xplot, 0, mKh[0, row_to_plot, :], alpha=0.25, color='blue',\n",
    "#                  label='layer 1', lw=0.75, step='mid')\n",
    "dum = ax1.set_xlabel('Distance in meters')\n",
    "# dum = ax2.set_yscale('log')\n",
    "# dum = ax2.set_ylabel('Hydraulic conductivity\\n in layer 1, in meters / day')\n",
    "\n",
    "line = '{}_xs.png'.format(metadata['HUC8_name'])\n",
    "fig_name = os.path.join(line)\n",
    "plt.savefig(fig_name)\n",
    "\n",
    "i = Image(filename=fig_name)\n",
    "i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T17:52:41.739107Z",
     "start_time": "2021-12-28T17:52:41.461763Z"
    }
   },
   "outputs": [],
   "source": [
    "grid = os.path.join(metadata['gis_dir'], 'ibound.tif')\n",
    "mtg = gmu.SourceProcessing(np.nan)\n",
    "mtg.read_raster(grid)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(11, 8.5))\n",
    "\n",
    "mask = (ibound == 0) | ~topo_cells\n",
    "mt = np.ma.MaskedArray(topo_cells, mask)\n",
    "cmap = colors.ListedColormap(['green'])\n",
    "im = ax.pcolormesh(mtg.x_edge, mtg.y_edge, mt, cmap=cmap, alpha=0.2, edgecolors=None)\n",
    "mask = (ibound == 0) | ~topo_error\n",
    "mte = np.ma.MaskedArray(topo_error, mask)\n",
    "cmap = colors.ListedColormap(['green'])\n",
    "# dum = ax[0].imshow(mte, cmap=cmap)\n",
    "im = ax.pcolormesh(mtg.x_edge, mtg.y_edge, mte, cmap=cmap, alpha=0.4, edgecolors=None)\n",
    "\n",
    "mask = (ibound == 0) | ~hydro_cells\n",
    "mh = np.ma.MaskedArray(hydro_cells, mask)\n",
    "cmap = colors.ListedColormap(['blue'])\n",
    "im = ax.pcolormesh(mtg.x_edge, mtg.y_edge, mh, cmap=cmap, alpha=0.2, edgecolors=None)\n",
    "mask = (ibound == 0) | ~hydro_error\n",
    "mhe = np.ma.MaskedArray(hydro_error, mask)\n",
    "cmap = colors.ListedColormap(['blue'])\n",
    "im = ax.pcolormesh(mtg.x_edge, mtg.y_edge, mhe, cmap=cmap, alpha=0.6, edgecolors=None)\n",
    "\n",
    "ax.set_aspect(1)\n",
    "\n",
    "dum = fig.suptitle('Default model errors\\n{} model\\nFraction dry drains (blue) {:0.2f}\\n \\\n",
    "Fraction flooded cells (green) {:0.2f}'.format( \\\n",
    " metadata['HUC8_name'], hydro_rate, topo_rate))\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "line = '{}_error_map.png'.format(metadata['HUC8_name'])   #csc\n",
    "fig_name = os.path.join(line)\n",
    "plt.savefig(fig_name)\n",
    "\n",
    "i = Image(filename=fig_name)\n",
    "i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "state": {
    "214ab2ebbcd04e0281e98ae00680ad31": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
