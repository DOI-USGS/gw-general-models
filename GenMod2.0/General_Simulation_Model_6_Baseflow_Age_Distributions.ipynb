{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T17:05:27.396853Z",
     "start_time": "2021-12-29T17:05:24.812400Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import os\n",
    "import datetime as dt\n",
    "import pickle, joblib\n",
    "\n",
    "\n",
    "# Standard data science libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import scipy.optimize as so \n",
    "import scipy.interpolate as si\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-notebook')\n",
    "\n",
    "# Options for pandas\n",
    "pd.options.display.max_columns = 20\n",
    "pd.options.display.max_rows = 200\n",
    "\n",
    "# Display all cell outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import Math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T17:05:28.685187Z",
     "start_time": "2021-12-29T17:05:27.429930Z"
    }
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact, Dropdown\n",
    "from IPython.display import display\n",
    "\n",
    "import flopy as fp\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString, MultiLineString, Point\n",
    "\n",
    "import RTD_util6 as rtd_ut\n",
    "import Genmod_Utilities as gmu\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as mticks\n",
    "\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell sets color and font defaults that work for AGU journals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T17:05:39.055720Z",
     "start_time": "2021-12-29T17:05:39.044549Z"
    }
   },
   "outputs": [],
   "source": [
    "KS1 = '#06366E'\n",
    "KS2 = '#00A3EB'\n",
    "KS3 = '#25C0A6'\n",
    "KS4 = '#FDDA58'\n",
    "KS5 = '#5D171A'\n",
    "\n",
    "font = {'family' : 'sans-serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 12,\n",
    "        'sans-serif' : 'Arial'}\n",
    "\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the location of the MODPATH7 executable file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T17:05:40.158018Z",
     "start_time": "2021-12-29T17:05:40.146556Z"
    }
   },
   "outputs": [],
   "source": [
    "mp_exe_name7 = '../Executables/modpath_7_2_001/bin/mpath7.exe'\n",
    "model_ws = 'optimal_model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read some files that were created in previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T17:05:42.453395Z",
     "start_time": "2021-12-29T17:05:42.423171Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('GenMod_metadata.txt') as json_file:\n",
    "    metadata = json.load(json_file)\n",
    "    \n",
    "src = os.path.join('model_ws', 'gsm_metadata.json')\n",
    "with open(src, 'r') as f:\n",
    "    gsm_metadata = json.load(f)   \n",
    "    \n",
    "from argparse import Namespace\n",
    "meta = Namespace(**gsm_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use General Simulation Model to calculate TTD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read MODFLOW model and create RTD object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T17:05:44.429467Z",
     "start_time": "2021-12-29T17:05:43.964535Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Reading model information')\n",
    "\n",
    "ml = fp.mf6.MFSimulation.load(sim_name='mfsim.nam', version='mf6', exe_name=metadata['modflow_path'],\n",
    "                              sim_ws='optimal_model', strict=True, verbosity_level=0, load_only=None, verify_data=False)\n",
    "model = ml.get_model()\n",
    "rtd = rtd_ut.RTD_util(ml, 'flow', 'rt')\n",
    "print('   ... done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read model output and compute net inflow to drain cells. This cell reads baseflow nflow to stream segments and attaches the values to the NHD stream segments. The resulting shapefile is called `drain_flows` and will be placed in `optimal_model` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T17:05:56.922928Z",
     "start_time": "2021-12-29T17:05:50.038398Z"
    }
   },
   "outputs": [],
   "source": [
    "# read shapefile created in step 1--NHD flowlines intersected with model grid\n",
    "src = os.path.join('gis', 'drain_segments.shp')\n",
    "shp = gpd.read_file(src)\n",
    "\n",
    "# read shapefile created in step 1--NHD flowlines intersected with model grid\n",
    "src = os.path.join('gis', 'nhd_clip.shp')\n",
    "nhd = gpd.read_file(src)\n",
    "nhd_crs = nhd.crs\n",
    "\n",
    "# read shapefile created in step 1--NHD flowlines intersected with model grid\n",
    "domain = gpd.read_file(metadata['domain_name'])\n",
    "domain.to_crs(crs=nhd_crs, inplace=True)\n",
    "\n",
    "# read enhanced model_grid file in model_ws\n",
    "src = os.path.join('gis', 'model_grid.csv')\n",
    "data = pd.read_csv(src)\n",
    "\n",
    "# extract the drain budget terms from modflow output\n",
    "rtd.get_budget('DRN')\n",
    "drains = rtd.budget\n",
    "\n",
    "# create a dataframe of drain flows\n",
    "drn_df = pd.DataFrame(drains[0])\n",
    "drn_df['node'] = drn_df['node'] - 1\n",
    "\n",
    "# merge drain segments (by model cells) with drain flows\n",
    "shp_drn_df = shp.merge(drn_df, left_on='node', right_on='node', how='outer')\n",
    "shp_drn_df = shp_drn_df[shp_drn_df.q < 0]\n",
    "\n",
    "# save shapefile to model_ws\n",
    "dst = os.path.join('optimal_model', 'drain_flows.shp')\n",
    "shp_drn_df.to_file(dst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the modified endpoint information. A modified endpoint file was created in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:18:23.304244Z",
     "start_time": "2021-12-29T16:18:09.670998Z"
    }
   },
   "outputs": [],
   "source": [
    "endpointfile = '{}_flow_rt_mod.mpend'.format(metadata['HUC8_name'])\n",
    "ep_data = pd.read_csv(os.path.join('optimal_model', endpointfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following line is necessary because of a bug in Flopy 3.3.2.  Hopefully the bug will be fixed in future versions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:18:23.335340Z",
     "start_time": "2021-12-29T16:18:23.306277Z"
    }
   },
   "outputs": [],
   "source": [
    "ep_data['Particle ID'] = ep_data['Particle ID'] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create functions that will be used to summarize age data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:18:23.351249Z",
     "start_time": "2021-12-29T16:18:23.337195Z"
    }
   },
   "outputs": [],
   "source": [
    "def meantt(x):\n",
    "    return np.mean(x)\n",
    "\n",
    "def mediantt(x):\n",
    "    return np.median(x)\n",
    "\n",
    "def fracyoung(x):\n",
    "    return (x < 65).sum() / x.shape[0]\n",
    "\n",
    "def meanyoung(x):\n",
    "    return x[x < 65].mean()\n",
    "\n",
    "def medianold(x):\n",
    "    return np.median(x[x >= 65])\n",
    "    \n",
    "def meanpath(x):\n",
    "    return np.mean(x)\n",
    "\n",
    "agg_func = {'rt': [meantt, mediantt, fracyoung, meanyoung , medianold], 'xyz_path_len': meanpath} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each stream segment may contain many particles.  The next cell groups the particle information by stream segment, thus creating a distribution of ages for each segment. The error message that gets generated is not important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:18:34.646461Z",
     "start_time": "2021-12-29T16:18:23.353247Z"
    }
   },
   "outputs": [],
   "source": [
    "nhd['Particle ID'] = nhd.NHDPlusID.astype(np.int64()).astype(str).str[-9:].astype(np.int32())\n",
    "summary = ep_data.groupby('Particle ID').agg(agg_func)\n",
    "nhd_age = summary.merge(nhd, left_index=True, right_on='Particle ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the column headers more understandable and set the coordinate reference system (CRS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:18:34.662482Z",
     "start_time": "2021-12-29T16:18:34.648375Z"
    }
   },
   "outputs": [],
   "source": [
    "rep_str = {('rt', 'meantt'): 'meantt', ('rt', 'mediantt'): 'mediantt',\n",
    " ('rt', 'fracyoung'): 'fracyoung', ('rt', 'meanyoung'): 'meanyoung', \n",
    " ('rt', 'medianold'): 'medianold', ('xyz_path_len', 'meanpath'): 'meanpath',\n",
    " 'maxft': 'maxstage', 'minft': 'minstage'}\n",
    "\n",
    "nhd_age.rename(columns=rep_str, inplace=True)\n",
    "\n",
    "nhd_age.set_index('Particle ID', inplace=True)\n",
    "\n",
    "nhd_age = gpd.GeoDataFrame(nhd_age[['meantt', 'mediantt', 'fracyoung', 'meanyoung', 'medianold', 'meanpath',\n",
    "       'StreamOrde',\n",
    "       'maxstage', 'minstage', \n",
    "       'geometry']])\n",
    "\n",
    "nhd_age.crs = nhd_crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell loops through each stream segment and fits one- and two-component Weibull distributions to the assemblage of particle travel times. This process smooths any irregularities in the travel time disitrbution caused by abrupt changes in properties in the MODFLOW model and makes the distribution continuous by filling the gaps where there were no particles. It only needs to be run once for each simulation. It takes about 30-60 minutes to run a typical HUC8 grid with 1000 km cells. It can be commented out for subsequent runs that may be done to tweak the graphs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:18:34.677693Z",
     "start_time": "2021-12-29T16:18:34.664333Z"
    }
   },
   "outputs": [],
   "source": [
    "# comid_dict = dict()\n",
    "\n",
    "# for comid, _df in ep_data.groupby('Particle ID'):\n",
    "#     t = _df.rt\n",
    "#     t.values.sort()\n",
    "#     n = t.shape[0]\n",
    "#     tt_cdf = np.linspace(1. / n, 1., n, endpoint=True)\n",
    "#     tmp = rtd.fit_dists(tt_cdf, t, [ss.weibull_min], fit_one=True, fit_two=True)\n",
    "#     comid_dict[comid] = tmp\n",
    "\n",
    "# dst = os.path.join(model_ws, 'comid_dict.pkl')\n",
    "# with open(dst, 'wb') as f:\n",
    "#     pickle.dump(comid_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell reads in a previously created travel time dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T17:06:15.383505Z",
     "start_time": "2021-12-29T17:06:13.970552Z"
    }
   },
   "outputs": [],
   "source": [
    "dst = os.path.join('optimal_model', 'comid_dict.pkl')\n",
    "with open(dst, 'rb') as f:\n",
    "    comid_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two-component Weibull distribution usually fits the particle travel time distribution much better than the one-conponent. The next cell adds the two-component parameters to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:18:53.856598Z",
     "start_time": "2021-12-29T16:18:36.101140Z"
    }
   },
   "outputs": [],
   "source": [
    "li = ['she', 'loe', 'sce', 'shl', 'lol', 'scl', 'f']\n",
    "df = pd.DataFrame()\n",
    "x = np.linspace(0, 10000, 10000)\n",
    "\n",
    "for key, value in comid_dict.items():\n",
    "    rt = value['tt']['rt']\n",
    "    num_values = rt.shape[0]\n",
    "    \n",
    "    pars = value['par']['two_weibull_min']\n",
    "    nhd_age.loc[key, li] = pars\n",
    "    \n",
    "#     w1 = ss.weibull_min(*pars[0:3])\n",
    "#     w2 = ss.weibull_min(*pars[3:6])\n",
    "#     pdf = (pars[6]) * w1.pdf(x) + (1-pars[6]) * w2.pdf(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataframe to a shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:18:56.907365Z",
     "start_time": "2021-12-29T16:18:53.857716Z"
    }
   },
   "outputs": [],
   "source": [
    "dst = os.path.join('optimal_model', 'nhd_age.shp')\n",
    "nhd_age.to_file(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:18:57.963215Z",
     "start_time": "2021-12-29T16:18:56.909030Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, sharex=True, sharey=True)\n",
    "\n",
    "var = 'fracyoung'\n",
    "dum = nhd.plot(ax=ax, linewidth=0.75, color='cornflowerblue')\n",
    "dum = gpd.GeoDataFrame(nhd_age).plot(column=var, legend=False, ax=ax, cmap=plt.cm.nipy_spectral, linewidth=1)\n",
    "dum = domain.plot(ax=ax, color='none', edgecolor='black')\n",
    "vmin=0\n",
    "vmax=1\n",
    "sm = plt.cm.ScalarMappable(cmap='nipy_spectral', norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "# fake up the array of the scalar mappable. Urgh...\n",
    "sm._A = []\n",
    "cbaxes = fig.add_axes([0.50, 0.85, 0.3, 0.025]) \n",
    "cb = fig.colorbar(sm, ax=ax, cax=cbaxes, orientation='horizontal')  \n",
    "ax.set_aspect(1)\n",
    "dum = fig.suptitle('Fraction of young water')\n",
    "# fig.set_tight_layout(True)\n",
    "\n",
    "dst = os.path.join('optimal_model', 'metric_maps_frac.png')\n",
    "plt.savefig(dst)\n",
    "\n",
    "Image(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:18:59.128756Z",
     "start_time": "2021-12-29T16:18:57.964066Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, sharex=True, sharey=True)\n",
    "\n",
    "var = 'meanyoung'\n",
    "dum = nhd.plot(ax=ax, linewidth=0.75, color='cornflowerblue')\n",
    "dum = gpd.GeoDataFrame(nhd_age).plot(column=var, legend=False, ax=ax, cmap=plt.cm.nipy_spectral, linewidth=1)\n",
    "dum = domain.plot(ax=ax, color='none', edgecolor='black')\n",
    "vmin=0\n",
    "vmax=65\n",
    "sm = plt.cm.ScalarMappable(cmap='nipy_spectral', norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "# fake up the array of the scalar mappable. Urgh...\n",
    "sm._A = []\n",
    "cbaxes = fig.add_axes([0.50, 0.85, 0.3, 0.025]) \n",
    "cb = fig.colorbar(sm, ax=ax, cax=cbaxes, orientation='horizontal')  \n",
    "ax.set_aspect(1)\n",
    "dum = fig.suptitle('Mean age of young water')\n",
    "# fig.set_tight_layout(True)\n",
    "\n",
    "dst = os.path.join('optimal_model', 'metric_maps_ageyoung.png')\n",
    "plt.savefig(dst)\n",
    "\n",
    "Image(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:18:59.979887Z",
     "start_time": "2021-12-29T16:18:59.129765Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, sharex=True, sharey=True)\n",
    "\n",
    "var = 'medianold'\n",
    "dum = nhd.plot(ax=ax, linewidth=0.75, color='cornflowerblue')\n",
    "dum = gpd.GeoDataFrame(nhd_age).plot(column=var, legend=False, ax=ax, cmap=plt.cm.nipy_spectral, linewidth=1)\n",
    "dum = domain.plot(ax=ax, color='none', edgecolor='black')\n",
    "vmin=65\n",
    "vmax=nhd_age[var].max()\n",
    "sm = plt.cm.ScalarMappable(cmap='nipy_spectral', norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "# fake up the array of the scalar mappable. Urgh...\n",
    "sm._A = []\n",
    "cbaxes = fig.add_axes([0.50, 0.85, 0.3, 0.025]) \n",
    "cb = fig.colorbar(sm, ax=ax, cax=cbaxes, orientation='horizontal')  \n",
    "ax.set_aspect(1)\n",
    "dum = fig.suptitle('Median age of old water')\n",
    "# fig.set_tight_layout(True)\n",
    "\n",
    "dst = os.path.join('optimal_model', 'metric_maps_medianold.png')\n",
    "plt.savefig(dst)\n",
    "\n",
    "Image(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:19:01.220825Z",
     "start_time": "2021-12-29T16:18:59.982744Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, sharex=True, sharey=True)\n",
    "\n",
    "var = 'meanpath'\n",
    "dum = nhd.plot(ax=ax, linewidth=0.75, color='cornflowerblue')\n",
    "dum = gpd.GeoDataFrame(nhd_age).plot(column=var, legend=False, ax=ax, cmap=plt.cm.nipy_spectral, linewidth=1)\n",
    "dum = domain.plot(ax=ax, color='none', edgecolor='black')\n",
    "vmin=0\n",
    "vmax=nhd_age[var].max()\n",
    "sm = plt.cm.ScalarMappable(cmap='nipy_spectral', norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "# fake up the array of the scalar mappable. Urgh...\n",
    "sm._A = []\n",
    "cbaxes = fig.add_axes([0.50, 0.85, 0.3, 0.025]) \n",
    "cb = fig.colorbar(sm, ax=ax, cax=cbaxes, orientation='horizontal')  \n",
    "ax.set_aspect(1)\n",
    "dum = fig.suptitle('Mean path length')\n",
    "# fig.set_tight_layout(True)\n",
    "\n",
    "dst = os.path.join('optimal_model', 'metric_maps_meanpath.png')\n",
    "plt.savefig(dst)\n",
    "\n",
    "Image(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:19:01.661298Z",
     "start_time": "2021-12-29T16:19:01.223701Z"
    }
   },
   "outputs": [],
   "source": [
    "nhd_age_df = pd.DataFrame(nhd_age)\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, sharex=True)\n",
    "dum = nhd_age_df.groupby('StreamOrde').median().plot(kind='bar', y='fracyoung', ax=ax[0,0], legend=False)\n",
    "dum = ax[0,0].set_ylabel('Fraction young water')\n",
    "\n",
    "dum = nhd_age_df.groupby('StreamOrde').median().plot(kind='bar', y='meanyoung', ax=ax[0,1], legend=False)\n",
    "dum = ax[0, 1].set_ylabel('Mean age of young water')\n",
    "\n",
    "dum = nhd_age_df.groupby('StreamOrde').median().plot(kind='bar', y='medianold', ax=ax[1,0], legend=False)\n",
    "dum = ax[1,0].set_xlabel('Stream order')\n",
    "dum = ax[1,0].set_ylabel('Median age of old water')\n",
    "\n",
    "dum = nhd_age_df.groupby('StreamOrde').median().plot(kind='bar', y='meanpath', ax=ax[1,1], legend=False)\n",
    "dum = ax[1,1].set_xlabel('Stream order')\n",
    "dum = ax[1,1].set_ylabel('Mean path length')\n",
    "\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "dst = os.path.join('optimal_model', 'bar_charts.png')\n",
    "plt.savefig(dst)\n",
    "# for i, label in enumerate(list(df.index)):\n",
    "#     score = df.ix[label]['Score']\n",
    "#     ax.annotate(str(score), (i, score + 0.2))\n",
    "\n",
    "Image(dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionary `comid_dict` or shapefile `nhd_age` can be used to calculate baseflow concentration and load. The procedure follows, and an example, but for wells, is given in \n",
    "\n",
    "    Starn, J.J., Kauffman, L.J., Carlson, C.S., Reddy, J.E., and Fienen, M.N., 2020, Data for three-dimensional distribution of groundwater residence time metrics in the glaciated United States using metamodels trained on general numerical simulation models: U.S. Geological Survey data release, https://doi.org/10.5066/P9BNWWCU.\n",
    "    \n",
    "* Create a time-series of dates and a corresponding data set of Julian (floating point) dates.\n",
    "* Interpolate the time-series of your input data onto the dates\n",
    "* Loop through `comid_dict` and extract the two-component Weibull parameters\n",
    "* Reconstruct the age distribution on the same dates and frequency as the input data\n",
    "* Use np.convolve to run the convolution between input and age distribution\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
